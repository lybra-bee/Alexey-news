#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import datetime
import os
import json
import time

class ContentGenerator:
    def __init__(self):
        self.hf_token = os.environ['HF_API_TOKEN']  # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω
        self.text_model = "mistralai/Mistral-7B-Instruct-v0.2"
        self.image_model = "stabilityai/stable-diffusion-xl-base-1.0"
        
    def wait_for_model(self, model_name, max_wait=300):
        """–û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        print(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ {model_name}...")
        
        headers = {"Authorization": f"Bearer {self.hf_token}"}
        url = f"https://api-inference.huggingface.co/models/{model_name}"
        
        start_time = time.time()
        while time.time() - start_time < max_wait:
            try:
                response = requests.get(url, headers=headers, timeout=30)
                if response.status_code == 200:
                    print("‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ")
                    return True
                elif response.status_code == 503:
                    print("üîÑ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è...")
                    time.sleep(10)
                else:
                    raise Exception(f"–û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: {response.status_code}")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
                time.sleep(10)
        
        raise Exception(f"–ú–æ–¥–µ–ª—å {model_name} –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å –∑–∞ {max_wait} —Å–µ–∫—É–Ω–¥")

    def generate_article(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ —á–µ—Ä–µ–∑ –Ω–µ–π—Ä–æ—Å–µ—Ç—å"""
        print("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏...")
        
        self.wait_for_model(self.text_model)
        
        headers = {
            "Authorization": f"Bearer {self.hf_token}",
            "Content-Type": "application/json"
        }
        
        prompt = """<s>[INST] –ù–∞–ø–∏—à–∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—É—é –Ω–æ–≤–æ—Å—Ç–Ω—É—é —Å—Ç–∞—Ç—å—é –Ω–∞ 300-400 —Å–ª–æ–≤ –æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è—Ö –≤ –æ–±–ª–∞—Å—Ç–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞. 
–û–ø–∏—à–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∫–æ–º–ø–∞–Ω–∏–∏ –∏ —Ä–µ–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è. –°—Ç–∞—Ç—å—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–π –∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ–π.
–§–æ—Ä–º–∞—Ç: –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤. [/INST]"""
        
        payload = {
            "inputs": prompt,
            "parameters": {
                "max_new_tokens": 600,
                "temperature": 0.8,
                "top_p": 0.9,
                "do_sample": True,
                "return_full_text": False
            },
            "options": {
                "wait_for_model": True
            }
        }
        
        response = requests.post(
            f"https://api-inference.huggingface.co/models/{self.text_model}",
            headers=headers,
            json=payload,
            timeout=120
        )
        
        response.raise_for_status()
        result = response.json()
        
        if not isinstance(result, list) or len(result) == 0:
            raise Exception("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
        
        article = result[0]['generated_text'].strip()
        article = article.replace('[INST]', '').replace('[/INST]', '')
        article = article.split('</s>')[0].strip()
        
        print("‚úÖ –°—Ç–∞—Ç—å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞")
        return article

    def generate_image(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –Ω–µ–π—Ä–æ—Å–µ—Ç—å"""
        print("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
        
        self.wait_for_model(self.image_model)
        
        headers = {
            "Authorization": f"Bearer {self.hf_token}",
            "Content-Type": "application/json"
        }
        
        prompt = "futuristic artificial intelligence, neural network concept, digital art, technology, glowing connections, blue and purple colors, high quality, 4k"
        
        payload = {
            "inputs": prompt,
            "parameters": {
                "width": 1024,
                "height": 512,
                "num_inference_steps": 25,
                "guidance_scale": 7.5,
                "negative_prompt": "blurry, low quality, text, watermark"
            },
            "options": {
                "wait_for_model": True
            }
        }
        
        response = requests.post(
            f"https://api-inference.huggingface.co/models/{self.image_model}",
            headers=headers,
            json=payload,
            timeout=180
        )
        
        response.raise_for_status()
        
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        image_filename = f"ai_image_{timestamp}.jpg"
        
        with open(image_filename, 'wb') as f:
            f.write(response.content)
        
        print("‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ")
        return image_filename

    def prepare_for_tilda(self, article_text, image_path):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Tilda"""
        print("üìù –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Tilda...")
        
        tilda_data = {
            "title": "–ù–æ–≤–æ—Å—Ç–∏ –ò–ò –∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π",
            "date": datetime.datetime.now().strftime("%d.%m.%Y %H:%M"),
            "content": article_text,
            "image_path": image_path,
            "short_description": article_text[:150] + "..." if len(article_text) > 150 else article_text,
            "tags": ["AI", "–Ω–µ–π—Ä–æ—Å–µ—Ç–∏", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ"],
            "generated_with_ai": True,
            "model_text": self.text_model,
            "model_image": self.image_model
        }
        
        with open('tilda_data.json', 'w', encoding='utf-8') as f:
            json.dump(tilda_data, f, ensure_ascii=False, indent=2)
        
        with open('article.txt', 'w', encoding='utf-8') as f:
            f.write(article_text)
        
        return tilda_data

    def generate_content(self):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
        print("üöÄ –ó–∞–ø—É—Å–∫ —á–∏—Å—Ç–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...")
        print(f"üîë –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–∫–µ–Ω: {self.hf_token[:10]}...")
        
        article_text = self.generate_article()
        print(f"üìÑ –î–ª–∏–Ω–∞ —Å—Ç–∞—Ç—å–∏: {len(article_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        image_path = self.generate_image()
        
        tilda_data = self.prepare_for_tilda(article_text, image_path)
        
        print("‚úÖ –ß–∏—Å—Ç–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        return tilda_data

def main():
    print("ü§ñ –ß–∏—Å—Ç—ã–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
    print("=" * 60)
    print("‚ö†Ô∏è  –ë–µ–∑ –∑–∞–≥–ª—É—à–µ–∫ –∏ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤")
    print("=" * 60)
    
    if 'HF_API_TOKEN' not in os.environ:
        raise Exception("HF_API_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    
    generator = ContentGenerator()
    result = generator.generate_content()
    
    print("\n" + "=" * 60)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ß–ò–°–¢–û–ô –ì–ï–ù–ï–†–ê–¶–ò–ò:")
    print(f"üìÑ –°—Ç–∞—Ç—å—è: {len(result['content'])} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {result['image_path']}")
    print(f"ü§ñ –ú–æ–¥–µ–ª—å —Ç–µ–∫—Å—Ç–∞: {result['model_text']}")
    print(f"üé® –ú–æ–¥–µ–ª—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {result['model_image']}")
    print("=" * 60)
    
    print("\nüìã –ü–†–ï–í–¨–Æ –°–¢–ê–¢–¨–ò:")
    print("=" * 40)
    print(result['content'][:200] + "...")
    print("=" * 40)

if __name__ == "__main__":
    main()
