#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
import datetime
import os
import json
import time

class ContentGenerator:
    def __init__(self):
        self.hf_token = os.environ['HF_API_TOKEN']
        # –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –†–ê–ë–û–¢–ê–Æ–©–ò–ï –ú–û–î–ï–õ–ò:
        self.text_model = "microsoft/DialoGPT-large"  # –†–∞–±–æ—Ç–∞–µ—Ç!
        self.image_model = "runwayml/stable-diffusion-v1-5"  # –†–∞–±–æ—Ç–∞–µ—Ç!
        
    def check_model_status(self, model_name):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –º–æ–¥–µ–ª–∏"""
        headers = {"Authorization": f"Bearer {self.hf_token}"}
        url = f"https://api-inference.huggingface.co/models/{model_name}"
        
        try:
            response = requests.get(url, headers=headers, timeout=10)
            return response.status_code
        except:
            return 500

    def generate_article(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ —á–µ—Ä–µ–∑ –Ω–µ–π—Ä–æ—Å–µ—Ç—å"""
        print("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
        status = self.check_model_status(self.text_model)
        if status != 200:
            raise Exception(f"–ú–æ–¥–µ–ª—å {self.text_model} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (—Å—Ç–∞—Ç—É—Å: {status})")
        
        headers = {
            "Authorization": f"Bearer {self.hf_token}",
            "Content-Type": "application/json"
        }
        
        prompt = "–ù–∞–ø–∏—à–∏ –Ω–æ–≤–æ—Å—Ç–Ω—É—é —Å—Ç–∞—Ç—å—é –æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è—Ö –≤ –æ–±–ª–∞—Å—Ç–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞:"
        
        payload = {
            "inputs": prompt,
            "parameters": {
                "max_length": 400,
                "temperature": 0.9,
                "do_sample": True,
                "return_full_text": False
            }
        }
        
        response = requests.post(
            f"https://api-inference.huggingface.co/models/{self.text_model}",
            headers=headers,
            json=payload,
            timeout=60
        )
        
        if response.status_code != 200:
            raise Exception(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: {response.status_code}")
        
        result = response.json()
        
        if not isinstance(result, list) or len(result) == 0:
            raise Exception("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏")
        
        article = result[0]['generated_text'].strip()
        print("‚úÖ –°—Ç–∞—Ç—å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞")
        return article

    def generate_image(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –Ω–µ–π—Ä–æ—Å–µ—Ç—å"""
        print("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
        status = self.check_model_status(self.image_model)
        if status != 200:
            raise Exception(f"–ú–æ–¥–µ–ª—å {self.image_model} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (—Å—Ç–∞—Ç—É—Å: {status})")
        
        headers = {
            "Authorization": f"Bearer {self.hf_token}",
            "Content-Type": "application/json"
        }
        
        prompt = "artificial intelligence, neural network, futuristic technology, digital art"
        
        payload = {
            "inputs": prompt,
            "parameters": {
                "width": 1024,
                "height": 512,
                "num_inference_steps": 20
            }
        }
        
        response = requests.post(
            f"https://api-inference.huggingface.co/models/{self.image_model}",
            headers=headers,
            json=payload,
            timeout=120
        )
        
        if response.status_code != 200:
            raise Exception(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {response.status_code}")
        
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        image_filename = f"ai_image_{timestamp}.jpg"
        
        with open(image_filename, 'wb') as f:
            f.write(response.content)
        
        print("‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ")
        return image_filename

    def prepare_for_tilda(self, article_text, image_path):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Tilda"""
        print("üìù –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Tilda...")
        
        tilda_data = {
            "title": "–ù–æ–≤–æ—Å—Ç–∏ –ò–ò –∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π",
            "date": datetime.datetime.now().strftime("%d.%m.%Y %H:%M"),
            "content": article_text,
            "image_path": image_path,
            "short_description": article_text[:150] + "..." if len(article_text) > 150 else article_text,
            "tags": ["AI", "–Ω–µ–π—Ä–æ—Å–µ—Ç–∏", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ"],
            "generated_with_ai": True,
            "model_text": self.text_model,
            "model_image": self.image_model
        }
        
        with open('tilda_data.json', 'w', encoding='utf-8') as f:
            json.dump(tilda_data, f, ensure_ascii=False, indent=2)
        
        with open('article.txt', 'w', encoding='utf-8') as f:
            f.write(article_text)
        
        return tilda_data

    def generate_content(self):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
        print("üöÄ –ó–∞–ø—É—Å–∫ —á–∏—Å—Ç–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...")
        print(f"üîë –¢–æ–∫–µ–Ω: {self.hf_token[:10]}...")
        print(f"üìù –ú–æ–¥–µ–ª—å —Ç–µ–∫—Å—Ç–∞: {self.text_model}")
        print(f"üé® –ú–æ–¥–µ–ª—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {self.image_model}")
        
        # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π
        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π...")
        text_status = self.check_model_status(self.text_model)
        image_status = self.check_model_status(self.image_model)
        
        print(f"üìù –¢–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å: {text_status}")
        print(f"üé® –ú–æ–¥–µ–ª—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {image_status}")
        
        if text_status != 200:
            raise Exception(f"–¢–µ–∫—Å—Ç–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {text_status}")
        if image_status != 200:
            raise Exception(f"–ú–æ–¥–µ–ª—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {image_status}")
        
        article_text = self.generate_article()
        print(f"üìÑ –î–ª–∏–Ω–∞ —Å—Ç–∞—Ç—å–∏: {len(article_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        image_path = self.generate_image()
        
        tilda_data = self.prepare_for_tilda(article_text, image_path)
        
        print("‚úÖ –ß–∏—Å—Ç–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        return tilda_data

def main():
    print("ü§ñ –ß–∏—Å—Ç—ã–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
    print("=" * 60)
    print("‚ö†Ô∏è  –ë–µ–∑ –∑–∞–≥–ª—É—à–µ–∫ –∏ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤")
    print("=" * 60)
    
    if 'HF_API_TOKEN' not in os.environ:
        raise Exception("HF_API_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    
    generator = ContentGenerator()
    result = generator.generate_content()
    
    print("\n" + "=" * 60)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ß–ò–°–¢–û–ô –ì–ï–ù–ï–†–ê–¶–ò–ò:")
    print(f"üìÑ –°—Ç–∞—Ç—å—è: {len(result['content'])} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {result['image_path']}")
    print(f"ü§ñ –ú–æ–¥–µ–ª—å —Ç–µ–∫—Å—Ç–∞: {result['model_text']}")
    print(f"üé® –ú–æ–¥–µ–ª—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {result['model_image']}")
    print("=" * 60)
    
    print("\nüìã –ü–†–ï–í–¨–Æ –°–¢–ê–¢–¨–ò:")
    print("=" * 40)
    print(result['content'][:200] + "...")
    print("=" * 40)

if __name__ == "__main__":
    main()
